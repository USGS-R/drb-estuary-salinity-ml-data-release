title: >-
  Data and deep learning/hydrodynamic model to support understanding and simulation of salinity dynamics in the Delaware Bay

abstract: >-
  Salinity dynamics in the Delaware Bay estuary are a critical water quality concern as elevated salinity can damage infrastructure and threaten drinking water supplies. Current state-of-the-art modeling approaches use hydrodynamic models, which can produce accurate results but are limited by significant computational costs. We developed a machine learning (ML) model to predict the 250 mg/L Cl- isochlor, also known as the salt front, using daily river discharge, meteorological drivers, and tidal water level data. We use the ML model to predict the location of the salt front, measured in river miles (RM) along the Delaware River, during the period 2001-2020, and we compare the ML model results to results from the hydrodynamic Coupled Ocean Atmospheric Wave Sediment Transport (COAWST) model. The ML model shows RMSE = 2.52 RM during the five-year holdout period, superior to three overlapping years of COAWST model predictions, RMSE = 5.36 RM, however the ML model struggles to predict extreme events. Further, we use functional performance and expected gradients, tools from information theory and explainable artificial intelligence, to show that the ML model learns physically realistic relationships between the salt front location and drivers (particularly discharge and tidal water level). These results demonstrate how an ML modeling approach can provide predictive and functional accuracy at a significantly reduced computational cost compared to process-based models. Additionally, these results provide support for using ML models for applications in operational forecasting, scenario testing, management decision making, hindcasting, and resulting opportunities to understand past behavior and develop hypotheses.

authors: ["Galen Gorski", "Salme Cook", "Amelia Snyder", "Alison P. Appling", "Theodore Thompson", "Jared D. Smith", "John C. Warner", "Simon N. Topp"]
pubdate: 2023 # replace with actual year, e.g., 2020
doi: https://doi.org/YY.XXXXX/XXXXXX # replace with actual DOI

build-environment: >-
  Multiple computer systems were used to generate these data, including linux, OSX. The open source languages R and Python were used on all systems.

# ----associated publication----
larger-cites:
  -
    authors: ["Salme E. Cook", "John C. Warner","Kendra L. Russell"]
    title: >-
      A numerical investigation of the mechanisms controlling salt intrusion in the Delaware Bay estuary
    form: publication
    pubdate: 2023
    link: https://doi.org/10.1016/j.ecss.2023.108257

# ----supporting publications----    
cross-cites:
  -
    authors: ["Luke A. Winslow","Gretchen J.A. Hansen","Jordan S. Read","Michael Notaro"]
    title: >-
      Large-scale modeled contemporary and future water temperature estimates for 10,774 Midwestern U.S. Lakes
    pubdate: 2017
    form: publication
    link: http://dx.doi.org/10.1038/sdata.2017.53

process-date: !expr format(Sys.time(),'%Y%m%d')
file-format: Four zipped folders and associated files.

entities:
  -
    data-name: README.md
    data-description: >-
      A markdown file detailing how to run the included workflow.
  -
    data-name: environment.yaml
    data-description: >-
      An environment yaml for creating a conda environment with the necessary libraries.
  -
    data-name: Snakefile_fetch_munge
    data-description: >-
      A snakemake workflow used to fetch and process data for machine learning model.
  -
    data-name: Snakefile_model_analysis
    data-description: >-
      A snakemake workflow used to analyze model performance using information theory analysis, expected gradients, and other techniques.
  -
    data-name: Snakefile_run_ml_model
    data-description: >-
      A snakemake workflow used to run machine learning model.
  -
    data-name: 01_fetch
    data-description: >-
      A directory containing data and code to retrieve data for machine learning model.
  -
    data-name: 01_fetch/params_config_fetch_noaa_nerrs.yaml
    data-description: >-
      A configuration file defining read, write and save location of NOAA NERRS meteorological data.
  -
    data-name: 01_fetch/params_config_fetch_noaa_nos.yaml
    data-description: >-
      A configuration file defining read, write and save location NOAA NOS tidal data.
  -
    data-name: 01_fetch/params_config_fetch_usgs_nwis.yaml
    data-description: >-
      A configuration file defining read, write and save location of USGS NWIS discharge data.
  -
    data-name: 01_fetch/wildcards_fetch_config.yaml
    data-description: >-
      A configuration file containing parameters to download NOAA NOS, NOAA NERRS and USGS NWIS data.
  -
    data-name: 01_fetch/in
    data-description: >-
      A directory to hold unprocessed input data for machine learning model that had to be manually downloaded.
  -
    data-name: 01_fetch/in/953860.zip
    data-description: >-
      A zipped directory containing meteorological data and metadata from the NOAA NERRS delsjmet station.
  -
    data-name: 01_fetch/src
    data-description: >-
      A directory containing python scripts for fetching and processing model data.
  -
    data-name: 01_fetch/src/fetch_coawst_model.py
    data-description: >-
      A python script containing functions to fetch model output from COAWST (source: XX).
  -
    data-name: 01_fetch/src/fetch_noaa_nerrs.py
    data-description: >-
      A python script containing functions to fetch data from NOAA's National Estuarine Research Reserve System (NERRS) (source: XX).
  -
    data-name: 01_fetch/src/fetch_noaa_nos.py
    data-description: >-
      A python script containing functions to fetch data from NOAA's National Ocean Service (NOS) (source: XX).
  -
    data-name: 01_fetch/src/fetch_usgs_nwis.py
    data-description: >-
      A python script containing functions to fetch water data from USGS's National Water Information system (NWIS) (source: XX).
  -
    data-name: 01_fetch/src/utils.py
    data-description: >-
      A python script with helper functions for retrieving and processing data.
  -
    data-name: 01_fetch/out
    data-description: >-
      A directory to hold unprocessed input data for machine learning model. These data may be reformatted versions of data from
      01_fetch/in or they may be data that was downloaded directly from the source through another mechanism, like an API. This
      directory is created by running this archive's pipeline (documented in the README.md).
  -
    data-name: 02_munge
    data-description: >-
      A directory containing python scripts and configuration files to process data for model.
  -
    data-name: 02_munge/params_config_fill_discharge_prms.yaml
    data-description: >-
      A configuration file for specifying which items to pull from ScienceBase to fill discharge at Trenton and Schuykill.
  -
    data-name: 02_munge/params_config_munge_noaa_nerrs.yaml
    data-description: >-
      A configuration file for processing NOAA NERRS data.
  -
    data-name: 02_munge/params_config_munge_noaa_nos.yaml
    data-description: >-
      A configuration file for processing NOAA NOS data.
  -
    data-name: 02_munge/params_config_munge_usgs_nwis.yaml
    data-description: >-
      A configuration file for processing USGS NWIS data.
  -
    data-name: 02_munge/src
    data-description: >-
      A directory containing python scripts to process retrieved data for model.
  -
    data-name: 02_munge/src/fill_discharge_prms.py
    data-description: >-
      A python script retrieving PRMS predictions of discharge (source: https://doi.org/10.31223/X55K7G) to fill NaNs in observed data. 
  -
    data-name: 02_munge/src/munge_noaa_nerrs.py
    data-description: >-
      A python script containing functions to process NOAA NERRS data for ingestion into the machine learning model.
  -
    data-name: 02_munge/src/munge_noaa_nos.py
    data-description: >-
      A python script containing functions to process NOAA NOS data for ingestion into the machine learning model.
  -
    data-name: 02_munge/src/munge_usgs_nwis.py
    data-description: >-
      A python script containing functions to process USGS NWIS data for ingestion into the machine learning model.
  -
    data-name: 02_munge/src/salt_front_record.R
    data-description: >-
      A R script containing functions to process daily and weekly salt front calculations from a historic record. 
  -
    data-name: 02_munge/out
    data-description: >-
      A directory to hold pre-processed input data for machine learning model. This directory is created by running 
      this archive's pipeline (documented in the README.md).
  -
    data-name: 03_model
    data-description: >-
      A directory containing python scripts, workflow files and configuration files for information theory analysis.
  -
    data-name: 03_model/hyperparameter_config.yaml
    data-description: >-
      A configuration file for hyperparameter optimization.
  -
    data-name: 03_model/model_config.yaml
    data-description: >-
      A configuration file for running machine learning model.
  -
    data-name: 03_model/model_config_Run_Manuscript_Results.yaml
    data-description: >-
      A snapshot of the configuration file that was used to run the machine learning model that produced the manuscript results.
      This conifguration file is used in the scripts in 04_analysis to produce the manuscript figures.
  -
    data-name: 03_model/in
    data-description: >-
      A directory containing a csv of daily salt front averages, weekly salt front averages and processed COAWST model output.
  -
    data-name: 03_model/in/saltfront_updated.csv
    data-description: >-
      XX
    attributes: 
    -
      attr-label: datetime
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: "2000-01-01"
      data-max: "2021-12-31"
      data-units: NA
    -
      attr-label: saltfront_daily
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 30.73
      data-max: 90.74
      data-units: XX
    -
      attr-label: saltfront7_weekly
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 30.73
      data-max: 89.75
      data-units: XX
  -
    data-name: 03_model/in/COAWST_model_runs/processed/COAWST_****_7day.csv
    data-description: >-
      XX
    attributes: 
    -
      attr-label: date
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: "2016-01-01"
      data-max: "2020-01-01"
      data-units: NA
    -
      attr-label: coawst_pred
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 47.2485103304761
      data-max: 86.0767010223214
      data-units: XX
  -
    data-name: 03_model/src
    data-description: >-
      A folder containing python scripts to run machine learning model.
  -
    data-name: 03_model/src/river_dl/preproc_utils.py
    data-description: >-
      XX
  -
    data-name: 03_model/src/LSTMDA_torch.py
    data-description: >-
      XX
  -
    data-name: 03_model/src/run_model.py
    data-description: >-
      XX
  -
    data-name: 03_model/out
    data-description: >-
      A folder containing the machine learning model output. Outputs from each run are stored in directories named after the run_id
      defined in model_config.yaml.
  -
    data-name: 03_model/out/Run_Manuscript_Results
    data-description: >-
      A folder containing the machine learning model output that was used in the associated manuscript. There are 10 replicates of
      the model, each stored in its own directory.
  -
    data-name: 03_model/out/Run_Manuscript_Results/inputs.zarr
    data-description: >-
      XX
  -
    data-name: 03_model/out/Run_Manuscript_Results/target.zarr
    data-description: >-
      XX
  -
    data-name: 03_model/out/Run_Manuscript_Results/prepped_model_io_data
    data-description: >-
      XX
  -
    data-name: 03_model/out/Run_Manuscript_Results/**/ModelResults.csv
    data-description: >-
      XX
    attributes: 
    -
      attr-label: saltfront_obs
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: XX
      data-max: XX
      data-units: XX
    -
      attr-label: saltfront_pred
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: XX
      data-max: XX
      data-units: XX
    -
      attr-label: train/val
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: NA
  -
    data-name: 03_model/out/Run_Manuscript_Results/**/ModelResultsTimeSeries.png
    data-description: >-
      XX
  -
    data-name: 03_model/out/Run_Manuscript_Results/**/losses.png
    data-description: >-
      XX
  -
    data-name: 03_model/out/Run_Manuscript_Results/**/model_param_output.txt
    data-description: >-
      XX
  -
    data-name: 03_model/out/Run_Manuscript_Results/**/weights.pt
    data-description: >-
      XX
  -
    data-name: 04_analysis
    data-description: >-
      A directory containing python scripts and configuration files for analyzing model performance including measuring
      functional performance and calculating expected gradients.
  -
    data-name: 04_analysis/src
    data-description: >-
      A folder containing python scripts to run information theory analysis and other analyses.
  -
    data-name: 04_analysis/src/XAI_functions.py
    data-description: >-
      XX
  -
    data-name: 04_analysis/src/estuary_salinity_functional_performance_func.py
    data-description: >-
      XX
  -
    data-name: 04_analysis/src/it_functions.py
    data-description: >-
      XX
  -
    data-name: 04_analysis/src/results.R
    data-description: >-
      XX
  -
    data-name: 04_analysis/src/results_functions.R
    data-description: >-
      XX
  -
    data-name: 04_analysis/out
    data-description: >-
      A directory to hold outputs of model performance analysis, including measuring functional performance and calculating 
      expected gradients. This directory is created by running this archive's pipeline (documented in the README.md).
  -
    data-name: 04_analysis/out/Test_run_functional_performance_df.csv
    data-description: >-
      XX
    attributes: 
    -
      attr-label: lag
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 0
      data-max: 9
      data-units: NA
    -
      attr-label: year
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 2001
      data-max: 2020
      data-units: NA
    -
      attr-label: source
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: NA
    -
      attr-label: Func_Perf
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: -0.227543205
      data-max: 0.145496753
      data-units: XX
    -
      attr-label: model
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: NA
  -
    data-name: 04_analysis/out/Test_run_it_df.csv
    data-description: >-
      XX
    attributes: 
    -
      attr-label: MI
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 0.111523764
      data-max: 0.493328032
      data-units: XX
    -
      attr-label: MIcrit
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 0.070052695
      data-max: 0.246378529
      data-units: XX
    -
      attr-label: TE
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: -3.00461E-16
      data-max: 0.50502906
      data-units: XX
    -
      attr-label: TEcrit
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 0
      data-max: 0.567124899
      data-units: XX
    -
      attr-label: corr
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: -0.903492321
      data-max: -0.140221919
      data-units: XX
    -
      attr-label: source
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: NA
    -
      attr-label: sink
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: NA
    -
      attr-label: year
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 2001
      data-max: 2020
      data-units: NA
    -
      attr-label: lag
      attr-def: >-
        XX
      attr-defs: >-
        This release
      data-min: 0
      data-max: 9
      data-units: NA

purpose: This release provides code and data for running a machine learning model to predict estuary salinity and using information theory, explainable AI, and comparison to other modeling approaches for analysis. 
start-date: 20000101
end-date: 20191231

update: none planned
themekeywords: ["machine learning", "deep learning", "hybrid modeling", "water","salt front", "Delaware River Basin","modeling", "salinity","coastal science","estuary", "information theory","explainable AI"]

usage-rules: >-
  These data are open access usable via creative commons as long as original data providers are acknowledged
  
data-publisher: U.S. Geological Survey
indirect-spatial: U.S.A.
latitude-res: 0.00001
longitude-res: 0.00001

# ----contacts----
contact-person: Galen A. Gorski
contact-phone: 703-648-5246
contact-fax: 443-498-5510
contact-email: ggorski@usgs.gov
contact-position: Machine Learning Specialist
contact-address: "12201 Sunrise Valley Drive"
contact-city: Reston
contact-state: VA
contact-zip: 20192

metadata-person: Galen A. Gorski
metadata-position: Machine Learning Specialist
metadata-phone: 703-648-5246
metadata-fax: 443-498-5510
metadata-email: ggorski@usgs.gov
metadata-address: "12201 Sunrise Valley Drive"
metadata-city: Reston
metadata-state: VA
metadata-zip: 20192
metadata-date: !expr format(Sys.time(),'%Y%m%d')

accur-test: No formal attribute accuracy tests were conducted.
funding-credits: >-
  This study was funded by the USGS.
  This research used resources of the Core Science Analytics and Synthesis Advanced Research Computing program at the U.S. Geological Survey.

process-description: >-
  This is a pipeline that generates a machine learning model for predicting the location of the 250 mg/L isochlor in the Delaware Bay Estuary using discharge, meteorological, and tidal observations. The pipeline is subdivided into four linked steps: 1) 01_fetch - fetches the appropriate data from online repositories 2) 02_munge - munges the data making it ready for use by the model 3) 03_model - trains the ML model and makes predictions and 4) 04_analysis - analyzes the results including a comparison to hydrodynamic model outputs. The steps can be run using the contained Snakemake files.
distro-person: Galen A. Gorski
liability-statement: >-
  Unless otherwise stated, all data, metadata and related materials are considered to satisfy the quality standards relative to the purpose for which the data were collected.
  Although these data and associated metadata have been reviewed for accuracy and completeness and approved for release by the U.S. Geological Survey (USGS),
  no warranty expressed or implied is made regarding the display or utility of the data on any other system or for general or scientific purposes, nor shall
  the act of distribution constitute any such warranty.
