title: >-
  Data and deep learning/hydrodynamic model to support understanding and simulation of salinity dynamics in the Delaware Bay

abstract: >-
  Salinity dynamics in the Delaware Bay estuary are a critical water quality concern as elevated salinity can damage infrastructure and threaten drinking water supplies. Current state-of-the-art modeling approaches use hydrodynamic models, which can produce accurate results but are limited by significant computational costs. We developed a machine learning (ML) model to predict the 250 mg/L Cl- isochlor, also known as the salt front, using daily river discharge, meteorological drivers, and tidal water level data. We use the ML model to predict the location of the salt front, measured in river miles (RM) along the Delaware River, during the period 2001-2020, and we compare the ML model results to results from the hydrodynamic Coupled Ocean Atmospheric Wave Sediment Transport (COAWST) model. The ML model shows RMSE = 2.52 RM during the five-year holdout period, superior to three overlapping years of COAWST model predictions, RMSE = 5.36 RM, however the ML model struggles to predict extreme events. Further, we use functional performance and expected gradients, tools from information theory and explainable artificial intelligence, to show that the ML model learns physically realistic relationships between the salt front location and drivers (particularly discharge and tidal water level). These results demonstrate how an ML modeling approach can provide predictive and functional accuracy at a significantly reduced computational cost compared to process-based models. Additionally, these results provide support for using ML models for applications in operational forecasting, scenario testing, management decision making, hindcasting, and resulting opportunities to understand past behavior and develop hypotheses.

authors: ["Galen Gorski", "Salme Cook", "Amelia Snyder", "Alison P. Appling", "Theodore Thompson", "Jared D. Smith", "John C. Warner", "Simon N. Topp"]
pubdate: 2023 # replace with actual year, e.g., 2020
doi: https://doi.org/YY.XXXXX/XXXXXX # replace with actual DOI

build-environment: >-
  Multiple computer systems were used to generate these data, including linux, OSX. The open source languages R and Python were used on all systems.

# ----associated publication----
larger-cites:
  -
    authors: ["Salme E. Cook", "John C. Warner","Kendra L. Russell"]
    title: >-
      "A numerical investigation of the mechanisms controlling salt intrusion in the Delaware Bay estuary"
    pubdate: 2023
    journal: "Estuarine, Coastal and Shelf Science"
    link: https://doi.org/10.1016/j.ecss.2023.108257

  -
    authors: ["Delaware River Basin Commission"]
    title: >-
      Salt Front Calculation Method (documentation and data available upon request).
    pubdate: 2023
    link: https://www.nj.gov/drbc/contact/
    
  -
    authors: ["XX"]
    title: >-
      NOAA NOS
    pubdate: XX
    link: XX

  -
    authors: ["XX"]
    title: >-
      NOAA NERRS
    pubdate: XX
    link: XX
    
  -
    authors: ["U.S. Geological Survey"]
    title: >-
      National Water Information System
    pubdate: 2016
    link: http://waterdata.usgs.gov/nwis/
 
   -
    authors: ["U.S. Geological Survey"]
    title: >-
      COAWST
    pubdate: XX
    link: XX

   -
    authors: ["Jacob Zwart", "Samantha Kay Oliver", "William David Watkins", "Jeffrey Michael Sadler", "Alison Paige Appling", "Hayley Rikert Corson-Dosch", " Xiaowei Jia", "Vipin Kumar", "Jordan S. Read"]
    title: >-
      Near-term forecasts of stream temperature using process-guided deep learning and data assimilation.
    pubdate: 2021
    link: https://doi.org/10.31223/X55K7G

# ----supporting publications----    
cross-cites:
  -
    authors: ["Galen Gorski","Salme Cook","Amelia Snyder","Alison P. Appling","Theodore Thompson","Jared D. Smith","John Warner", "Simon N. Topp"]
    title: >-
      XX - paper title
    pubdate: 2023
    form: publication
    link: XX

process-date: !expr format(Sys.time(),'%Y%m%d')
file-format: Four zipped folders and associated files.

entities:
  -
    data-name: 01_fetch.zip
    data-description: A zipped file containing data and code to retrieve additional data for machine learning model.
    attributes:
    -
      attr-label: in
      attr-def: A folder to hold a zip file containing meteorological data (which contains its own readme file). 
    data-name: README.md
    data-description: >-
      A markdown file detailing how to run the included workflow.
  -
    data-name: environment.yaml
    data-description: >-
      An environment yaml for creating a conda environment with the necessary libraries.
  -
    data-name: Snakefile_fetch_munge
    data-description: >-
      A snakemake workflow used to fetch and process data for machine learning model.
  -
    data-name: Snakefile_model_analysis
    data-description: >-
      A snakemake workflow used to analyze model performance using information theory analysis, expected gradients, and other techniques.
  -
    data-name: Snakefile_run_ml_model
    data-description: >-
      A snakemake workflow used to run machine learning model.
  -
    data-name: 01_fetch
    data-description: >-
      A directory containing data and code to retrieve data for machine learning model.
  -
    data-name: 01_fetch/params_config_fetch_noaa_nerrs.yaml
    data-description: >-
      A configuration file defining read, write and save location of NOAA NERRS meteorological data.
  -
    data-name: 01_fetch/params_config_fetch_noaa_nos.yaml
    data-description: >-
      A configuration file defining read, write and save location NOAA NOS tidal data.
  -
    data-name: 01_fetch/params_config_fetch_usgs_nwis.yaml
    data-description: >-
      A configuration file defining read, write and save location of USGS NWIS discharge data.
  -
    data-name: 01_fetch/wildcards_fetch_config.yaml
    data-description: >-
      A configuration file containing parameters to download NOAA NOS, NOAA NERRS and USGS NWIS data.
  -
    data-name: 01_fetch/in
    data-description: >-
      A directory to hold unprocessed input data for machine learning model that had to be manually downloaded.
  -
    data-name: 01_fetch/in/953860.zip
    data-description: >-
      A zipped directory containing meteorological data and metadata from the NOAA NERRS delsjmet station.
  -
    data-name: 01_fetch/src
    data-description: >-
      A directory containing python scripts for fetching and processing model data.
  -
    data-name: 01_fetch/src/fetch_coawst_model.py
    data-description: >-
      A python script containing functions to fetch model output from COAWST (source: XX).
  -
    data-name: 01_fetch/src/fetch_noaa_nerrs.py
    data-description: >-
      A python script containing functions to fetch data from NOAA's National Estuarine Research Reserve System (NERRS) (source: XX).
  -
    data-name: 01_fetch/src/fetch_noaa_nos.py
    data-description: >-
      A python script containing functions to fetch data from NOAA's National Ocean Service (NOS) (source: XX).
  -
    data-name: 01_fetch/src/fetch_usgs_nwis.py
    data-description: >-
      A python script containing functions to fetch water data from USGS's National Water Information system (NWIS) (source: U.S. Geological Survey, 2016).
  -
    data-name: 01_fetch/src/utils.py
    data-description: >-
      A python script with helper functions for retrieving and processing data.
  -
    data-name: 01_fetch/out
    data-description: >-
      A directory to hold unprocessed input data for machine learning model. These data may be reformatted versions of data from
      01_fetch/in or they may be data that was downloaded directly from the source through another mechanism, like an API. This
      directory is created by running this archive's pipeline (documented in the README.md).
  -
    data-name: 02_munge
    data-description: >-
      A directory containing python scripts and configuration files to process data for model.
  -
    data-name: 02_munge/params_config_fill_discharge_prms.yaml
    data-description: >-
      A configuration file for specifying which items to pull from ScienceBase to fill discharge at Trenton and Schuykill.
  -
    data-name: 02_munge/params_config_munge_noaa_nerrs.yaml
    data-description: >-
      A configuration file for processing NOAA NERRS data.
  -
    data-name: 02_munge/params_config_munge_noaa_nos.yaml
    data-description: >-
      A configuration file for processing NOAA NOS data.
  -
    data-name: 02_munge/params_config_munge_usgs_nwis.yaml
    data-description: >-
      A configuration file for processing USGS NWIS data.
  -
    data-name: 02_munge/src
    data-description: >-
      A directory containing python scripts to process retrieved data for model.
  -
    data-name: 02_munge/src/fill_discharge_prms.py
    data-description: >-
      A python script retrieving PRMS predictions of discharge (source: Zwart and others, 2021) to fill NaNs in observed data. 
  -
    data-name: 02_munge/src/munge_noaa_nerrs.py
    data-description: >-
      A python script containing functions to process NOAA NERRS data for ingestion into the machine learning model.
  -
    data-name: 02_munge/src/munge_noaa_nos.py
    data-description: >-
      A python script containing functions to process NOAA NOS data for ingestion into the machine learning model.
  -
    data-name: 02_munge/src/munge_usgs_nwis.py
    data-description: >-
      A python script containing functions to process USGS NWIS data for ingestion into the machine learning model.
  -
    data-name: 02_munge/src/salt_front_record.R
    data-description: >-
      An R script that preprocesses daily and 7-day backward-looking average values of salt front location (source: Delaware River Basin Commission, 2023). Preprocessing includes renaming columns and subsetting time series to only include values in or after the year 2000. 
  -
    data-name: 02_munge/out
    data-description: >-
      A directory to hold pre-processed input data for machine learning model. This directory is created by running 
      this archive's pipeline (documented in the README.md).
  -
    data-name: 03_model
    data-description: >-
      A directory containing python scripts, workflow files and configuration files for information theory analysis.
  -
    data-name: 03_model/hyperparameter_config.yaml
    data-description: >-
      A configuration file for hyperparameter optimization.
  -
    data-name: 03_model/model_config.yaml
    data-description: >-
      A configuration file for running machine learning model.
  -
    data-name: 03_model/model_config_Run_Manuscript_Results.yaml
    data-description: >-
      A snapshot of the configuration file that was used to run the machine learning model that produced the manuscript results.
      This conifguration file is used in the scripts in 04_analysis to produce the manuscript figures.
  -
    data-name: 03_model/in
    data-description: >-
      A directory containing a csv of daily salt front averages, weekly salt front averages and processed COAWST model output.
  -
    data-name: 03_model/in/saltfront_updated.csv
    data-description: >-
      a record of the salt front location in units of river mile, provided by the Delaware River Basin Commission
    attributes: 
    -
      attr-label: datetime
      attr-def: >-
        date
      attr-defs: >-
        This release
      data-min: "2000-01-01"
      data-max: "2021-12-31"
      data-units: date YYYY-MM-DD
    -
      attr-label: saltfront_daily
      attr-def: >-
        Daily record of the salt front location
      attr-defs: >-
        This release
      data-min: 30.73
      data-max: 90.74
      data-units: river miles
    -
      attr-label: saltfront7_weekly
      attr-def: >-
        7-day backward looking average of the salt front location
      attr-defs: >-
        This release
      data-min: 30.73
      data-max: 89.75
      data-units: river miles
  -
    data-name: 03_model/in/COAWST_model_runs/processed/COAWST_****_7day.csv
    data-description: >-
      Prediction of salt front location from COAWST model for three years 2016, 2018, and 2019 each in a separate .csv file
    attributes: 
    -
      attr-label: date
      attr-def: >-
        date
      attr-defs: >-
        This release
      data-min: "2016-01-01"
      data-max: "2020-01-01"
      data-units: 
    -
      attr-label: coawst_pred
      attr-def: >-
        7-day average salt front location predictions from COAWST 
      attr-defs: >-
        This release
      data-min: 47.2485103304761
      data-max: 86.0767010223214
      data-units: date MM-DD-YYYY
  -
    data-name: 03_model/src
    data-description: >-
      A folder containing python scripts to run machine learning model.
  -
    data-name: 03_model/src/river_dl/preproc_utils.py
    data-description: >-
      a python script containing functions for preprocessing data for modeling from the river-dl submodule
  -
    data-name: 03_model/src/LSTMDA_torch.py
    data-description: >-
      a python script containing functions for the training and evaluation of the LSTM
  -
    data-name: 03_model/src/run_model.py
    data-description: >-
      a python script with functions for processing data, training the model, and processing the results
  -
    data-name: 03_model/out
    data-description: >-
      A folder containing the machine learning model output. Outputs from each run are stored in directories named after the run_id
      defined in model_config.yaml.
  -
    data-name: 03_model/out/Run_Manuscript_Results
    data-description: >-
      A folder containing the machine learning model output that was used in the associated manuscript. There are 10 replicates of
      the model, each stored in its own directory.
  -
    data-name: 03_model/out/Run_Manuscript_Results/inputs.zarr
    data-description: >-
      time series of inputs for the model
  -
    data-name: 03_model/out/Run_Manuscript_Results/target.zarr
    data-description: >-
      time series of the modeling target (salt front location)
  -
    data-name: 03_model/out/Run_Manuscript_Results/prepped_model_io_data
    data-description: >-
      inputs and targets merged and prepared for model training
  -
    data-name: 03_model/out/Run_Manuscript_Results/{replicate}/ModelResults.csv
    data-description: >-
      Daily prediction of 7-day backward-looking average salt front location for each model replicate.
    attributes: 
    -
      attr-label: saltfront_obs
      attr-def: >-
        observed daily 7-day average location of the salt front 
      attr-defs: >-
        This release
      data-min: 54.08
      data-max: 89.75
      data-units: river mile
    -
      attr-label: saltfront_pred
      attr-def: >-
        daily prediction of 7-day average salt front location for model replicate **
      attr-defs: >-
        This release
      data-min: 56.50
      data-max: 88.15
      data-units: river mile
    -
      attr-label: train/val
      attr-def: >-
        indicator if the days prediction falls into the training or validation time period
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: None
  -
    data-name: 03_model/out/Run_Manuscript_Results/**/ModelResultsTimeSeries.png
    data-description: >-
      a plot of the time series of observed and predicted salt front location for each model replicate
  -
    data-name: 03_model/out/Run_Manuscript_Results/**/losses.png
    data-description: >-
      a plot of the validation losses for each epoch during the model training
  -
    data-name: 03_model/out/Run_Manuscript_Results/**/model_param_output.txt
    data-description: >-
      a parameter file that shows the model hyperparameters and other modeling parameters used for model training
  -
    data-name: 03_model/out/Run_Manuscript_Results/**/weights.pt
    data-description: >-
      the trained weights of the model for each replicate
  -
    data-name: 04_analysis
    data-description: >-
      A directory containing python scripts and configuration files for analyzing model performance including measuring
      functional performance and calculating expected gradients.
  -
    data-name: 04_analysis/src
    data-description: >-
      A folder containing python scripts to run information theory analysis and other analyses.
  -
    data-name: 04_analysis/src/XAI_functions.py
    data-description: >-
      a python script with functions for applying XAI techniques to the model
  -
    data-name: 04_analysis/src/estuary_salinity_functional_performance_func.py
    data-description: >-
      a python script that executes the functional performance calculations for the model output and COAWST model output
  -
    data-name: 04_analysis/src/it_functions.py
    data-description: >-
      a python script with functions to calculate information theory based metrics such as mutual information and transfer entropy
  -
    data-name: 04_analysis/src/results.R
    data-description: >-
      an R script for generating the figures from the manuscript
  -
    data-name: 04_analysis/src/results_functions.R
    data-description: >-
      an R script with functions to use in results.R for generating the figures from the manuscript
  -
    data-name: 04_analysis/out
    data-description: >-
      A directory to hold outputs of model performance analysis, including measuring functional performance and calculating 
      expected gradients. This directory is created by running this archive's pipeline (documented in the README.md).
  -
    data-name: 04_analysis/out/Test_run_functional_performance_df.csv
    data-description: >-
      a csv with functional performance calculations for each source/sink/year combination by subtracting the modeled transfer entropy from the observed
    attributes: 
    -
      attr-label: lag
      attr-def: >-
        the number of timestamps (days) to lag the sink from the source for the calculation
      attr-defs: >-
        This release
      data-min: 0
      data-max: 9
      data-units: days
    -
      attr-label: year
      attr-def: >-
        the year to run the calculations for
      attr-defs: >-
        This release
      data-min: 2001
      data-max: 2020
      data-units: NA
    -
      attr-label: source
      attr-def: >-
        list of column names to use as sources
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: NA
    -
      attr-label: Func_Perf
      attr-def: >-
        the calculated fucntional performance
      attr-defs: >-
        This release
      data-min: -0.227543205
      data-max: 0.145496753
      data-units: unitless since transfer entropy is of nats then normalized by the entropy of the sink variable
    -
      attr-label: model
      attr-def: >-
        the name of the model that is being assesseed
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: NA
  -
    data-name: 04_analysis/out/Test_run_it_df.csv
    data-description: >-
      a csv with the results from 
    attributes: 
    -
      attr-label: MI
      attr-def: >-
        mutual information between source and sink
      attr-defs: >-
        This release
      data-min: 0.111523764
      data-max: 0.493328032
      data-units: unitless since mutual information is of nats then normalized by the entropy of the sink variable
    -
      attr-label: MIcrit
      attr-def: >-
        The significance threshold for mutual information
      attr-defs: >-
        This release
      data-min: 0.070052695
      data-max: 0.246378529
      data-units: XX
    -
      attr-label: TE
      attr-def: >-
        transfer entropy between source and sink
      attr-defs: >-
        This release
      data-min: -3.00461E-16
      data-max: 0.50502906
      data-units: unitless since transfer entropy is of nats then normalized by the entropy of the sink variable
    -
      attr-label: TEcrit
      attr-def: >-
        the significance threshold for transfer entropy
      attr-defs: >-
        This release
      data-min: 0
      data-max: 0.567124899
      data-units: unitless since transfer entropy is of nats then normalized by the entropy of the sink variable
    -
      attr-label: corr
      attr-def: >-
        pearson correlation coefficient between source and sink
      attr-defs: >-
        This release
      data-min: -0.903492321
      data-max: -0.140221919
      data-units: unitless
    -
      attr-label: source
      attr-def: >-
        source variable (X) used for information theory calculations
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: NA
    -
      attr-label: sink
      attr-def: >-
        sink variable (Y) used for information theory calculations
      attr-defs: >-
        This release
      data-min: NA
      data-max: NA
      data-units: NA
    -
      attr-label: year
      attr-def: >-
        year used for information theory calculations
      attr-defs: >-
        This release
      data-min: 2001
      data-max: 2020
      data-units: NA
    -
      attr-label: lag
      attr-def: >-
        time lag for information theory calculations
      attr-defs: >-
        This release
      data-min: 0
      data-max: 9
      data-units: days

purpose: This release provides code and data for running a machine learning model to predict estuary salinity and using information theory, explainable AI, and comparison to other modeling approaches for analysis. 
start-date: 20000101
end-date: 20191231

update: none planned
themekeywords: ["machine learning", "deep learning", "hybrid modeling", "water","salt front", "Delaware River Basin","modeling", "salinity","coastal science","estuary", "information theory","explainable AI"]

usage-rules: >-
  These data are open access usable via creative commons as long as original data providers are acknowledged
  
data-publisher: U.S. Geological Survey
indirect-spatial: U.S.A.
latitude-res: 0.00001
longitude-res: 0.00001

# ----contacts----
contact-person: Galen A. Gorski
contact-phone: 703-648-5246
contact-fax: 443-498-5510
contact-email: ggorski@usgs.gov
contact-position: Machine Learning Specialist
contact-address: "12201 Sunrise Valley Drive"
contact-city: Reston
contact-state: VA
contact-zip: 20192

metadata-person: Galen A. Gorski
metadata-position: Machine Learning Specialist
metadata-phone: 703-648-5246
metadata-fax: 443-498-5510
metadata-email: ggorski@usgs.gov
metadata-address: "12201 Sunrise Valley Drive"
metadata-city: Reston
metadata-state: VA
metadata-zip: 20192
metadata-date: !expr format(Sys.time(),'%Y%m%d')

accur-test: No formal attribute accuracy tests were conducted.
funding-credits: >-
  This study was funded by the USGS.
  This research used resources of the Core Science Analytics and Synthesis Advanced Research Computing program at the U.S. Geological Survey.

process-description: >-
  This is a pipeline that generates a machine learning model for predicting the location of the 250 mg/L isochlor in the Delaware Bay Estuary using discharge, meteorological, and tidal observations. The pipeline is subdivided into four linked steps: 1) 01_fetch - fetches the appropriate data from online repositories 2) 02_munge - munges the data making it ready for use by the model 3) 03_model - trains the ML model and makes predictions and 4) 04_analysis - analyzes the results including a comparison to hydrodynamic model outputs. The steps can be run using the contained Snakemake files.
distro-person: Galen A. Gorski
liability-statement: >-
  Unless otherwise stated, all data, metadata and related materials are considered to satisfy the quality standards relative to the purpose for which the data were collected.
  Although these data and associated metadata have been reviewed for accuracy and completeness and approved for release by the U.S. Geological Survey (USGS),
  no warranty expressed or implied is made regarding the display or utility of the data on any other system or for general or scientific purposes, nor shall
  the act of distribution constitute any such warranty.
